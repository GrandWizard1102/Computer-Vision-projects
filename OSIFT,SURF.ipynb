{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "\n",
    "def extract_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "\n",
    "def match_descriptors(descriptors1, descriptors2):\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return []\n",
    "\n",
    "    descriptors1 = np.float32(descriptors1)\n",
    "    descriptors2 = np.float32(descriptors2)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    return matches\n",
    "\n",
    "\n",
    "def classify_image(test_image_path, dataset_folder):\n",
    "    test_image = cv2.imread(test_image_path)\n",
    "    if test_image is None:\n",
    "        raise ValueError(f\"Failed to load test image at {test_image_path}\")\n",
    "\n",
    "    test_keypoints, test_descriptors = extract_features(test_image)\n",
    "    best_match_count = 0\n",
    "    best_class = None\n",
    "\n",
    "    \n",
    "    for class_name in os.listdir(dataset_folder):\n",
    "        class_folder = os.path.join(dataset_folder, class_name)\n",
    "\n",
    "        if os.path.isdir(class_folder):\n",
    "            total_matches = 0\n",
    "\n",
    "            \n",
    "            for image_name in os.listdir(class_folder):\n",
    "                image_path = os.path.join(class_folder, image_name)\n",
    "                class_image = cv2.imread(image_path)\n",
    "\n",
    "                class_keypoints, class_descriptors = extract_features(class_image)\n",
    "\n",
    "                \n",
    "                matches = match_descriptors(test_descriptors, class_descriptors)\n",
    "                total_matches += len(matches)\n",
    "\n",
    "\n",
    "            if total_matches > best_match_count:\n",
    "                best_match_count = total_matches\n",
    "                best_class = class_name\n",
    "\n",
    "    return best_class, best_match_count\n",
    "\n",
    "\n",
    "test_image_path = r'C:\\Users\\student\\Desktop\\CV20\\test2.jpg'\n",
    "dataset_folder = r'C:\\Users\\student\\Downloads\\archive (5)\\geometric shapes dataset'\n",
    "\n",
    "\n",
    "try:\n",
    "    best_class, match_count = classify_image(test_image_path, dataset_folder)\n",
    "    print(f\"The test image is classified as: {best_class} with {match_count} matches.\")\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c131cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "MIN_MATCH_COUNT = 3\n",
    "\n",
    "\n",
    "img2 = cv2.imread(r\"C:\\Users\\madhu\\Downloads\\objects.jpeg\") \n",
    "img1 = cv2.imread(r\"C:\\Users\\madhu\\OneDrive\\Pictures\\Screenshots\\Screenshot 2025-03-17 211340.png\")  \n",
    "\n",
    "\n",
    "img_rgb = img2.copy()\n",
    "\n",
    "\n",
    "alg = cv2.SIFT_create()  \n",
    "\n",
    "\n",
    "kp1, des1 = alg.detectAndCompute(img1, None)\n",
    "kp2, des2 = alg.detectAndCompute(img2, None)\n",
    "\n",
    "\n",
    "x = np.array([kp2[0].pt])\n",
    "\n",
    "for i in range(len(kp2)):\n",
    "    x = np.append(x, [kp2[i].pt], axis=0)\n",
    "\n",
    "x = x[1:len(x)]  \n",
    "\n",
    "\n",
    "bandwidth = estimate_bandwidth(x, quantile=0.1, n_samples=500)\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True, cluster_all=True)\n",
    "ms.fit(x)\n",
    "\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "labels_unique = np.unique(labels)\n",
    "\n",
    "n_clusters_ = len(labels_unique)\n",
    "print(\"Number of estimated clusters: %d\" % n_clusters_)\n",
    "\n",
    "\n",
    "s = [None] * n_clusters_\n",
    "for i in range(n_clusters_):\n",
    "    l = ms.labels_\n",
    "\n",
    "    d, = np.where(l == i)\n",
    "\n",
    "    s[i] = list(kp2[xx] for xx in d)\n",
    "\n",
    "des2_ = des2\n",
    "\n",
    "\n",
    "for i in range(n_clusters_):\n",
    "    kp2 = s[i]\n",
    "\n",
    "    d, = np.where(labels == i)\n",
    "    des2 = des2_[d, :]\n",
    "\n",
    "    if len(kp2) < 2 or len(kp1) < 2:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    des1 = np.float32(des1)\n",
    "    des2 = np.float32(des2)\n",
    "\n",
    "    matches = flann.knnMatch(des1, des2, 2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.5 * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    \n",
    "    if len(good) > MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 2)\n",
    "\n",
    "        if M is None:\n",
    "            print(\"No Homography\")\n",
    "            continue\n",
    "\n",
    "       \n",
    "        h, w = img1.shape[:2]\n",
    "        corners = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
    "        transformedCorners = cv2.perspectiveTransform(corners, M)\n",
    "\n",
    "        x = int(transformedCorners[0][0][0])\n",
    "        y = int(transformedCorners[0][0][1])\n",
    "\n",
    "        \n",
    "        cv2.rectangle(img_rgb, (x, y), (x+w, y+h), (0, 0, 255), 3)\n",
    "        img2 = cv2.polylines(img2, [np.int32(transformedCorners)], True, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Template Image')\n",
    "plt.axis('off')\n",
    "plt.imshow(img1_rgb)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Scene Image with Detected Object')\n",
    "plt.axis('off')\n",
    "plt.imshow(img_rgb)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fbfa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
